Model : baseline_unet_do_0.0_activation_ReLU_
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 256, 256, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 256, 256, 32) 320         input_1[0][0]                    
__________________________________________________________________________________________________
re_lu_1 (ReLU)                  (None, 256, 256, 32) 0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 256, 256, 32) 0           re_lu_1[0][0]                    
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 256, 256, 32) 9248        dropout_1[0][0]                  
__________________________________________________________________________________________________
re_lu_2 (ReLU)                  (None, 256, 256, 32) 0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 256, 256, 32) 0           re_lu_2[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 32) 0           dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 128, 128, 64) 18496       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
re_lu_3 (ReLU)                  (None, 128, 128, 64) 0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 128, 128, 64) 0           re_lu_3[0][0]                    
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 128, 128, 64) 36928       dropout_3[0][0]                  
__________________________________________________________________________________________________
re_lu_4 (ReLU)                  (None, 128, 128, 64) 0           conv2d_4[0][0]                   
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 128, 128, 64) 0           re_lu_4[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 64)   0           dropout_4[0][0]                  
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
re_lu_5 (ReLU)                  (None, 64, 64, 128)  0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 64, 64, 128)  0           re_lu_5[0][0]                    
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 64, 64, 128)  147584      dropout_5[0][0]                  
__________________________________________________________________________________________________
re_lu_6 (ReLU)                  (None, 64, 64, 128)  0           conv2d_6[0][0]                   
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 64, 64, 128)  0           re_lu_6[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 128)  0           dropout_6[0][0]                  
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
re_lu_7 (ReLU)                  (None, 32, 32, 256)  0           conv2d_7[0][0]                   
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 32, 32, 256)  0           re_lu_7[0][0]                    
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 256)  590080      dropout_7[0][0]                  
__________________________________________________________________________________________________
re_lu_8 (ReLU)                  (None, 32, 32, 256)  0           conv2d_8[0][0]                   
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 32, 32, 256)  0           re_lu_8[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 256)  0           dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 16, 16, 512)  1180160     max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
re_lu_9 (ReLU)                  (None, 16, 16, 512)  0           conv2d_9[0][0]                   
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 16, 16, 512)  0           re_lu_9[0][0]                    
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 16, 16, 512)  2359808     dropout_9[0][0]                  
__________________________________________________________________________________________________
re_lu_10 (ReLU)                 (None, 16, 16, 512)  0           conv2d_10[0][0]                  
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 16, 16, 512)  0           re_lu_10[0][0]                   
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 256)  524544      dropout_10[0][0]                 
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 32, 32, 512)  0           conv2d_transpose_1[0][0]         
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 32, 32, 256)  1179904     concatenate_1[0][0]              
__________________________________________________________________________________________________
re_lu_11 (ReLU)                 (None, 32, 32, 256)  0           conv2d_11[0][0]                  
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 32, 32, 256)  0           re_lu_11[0][0]                   
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 32, 32, 256)  590080      dropout_11[0][0]                 
__________________________________________________________________________________________________
re_lu_12 (ReLU)                 (None, 32, 32, 256)  0           conv2d_12[0][0]                  
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 32, 32, 256)  0           re_lu_12[0][0]                   
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 128)  131200      dropout_12[0][0]                 
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 64, 256)  0           conv2d_transpose_2[0][0]         
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 64, 64, 128)  295040      concatenate_2[0][0]              
__________________________________________________________________________________________________
re_lu_13 (ReLU)                 (None, 64, 64, 128)  0           conv2d_13[0][0]                  
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 64, 64, 128)  0           re_lu_13[0][0]                   
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 64, 64, 128)  147584      dropout_13[0][0]                 
__________________________________________________________________________________________________
re_lu_14 (ReLU)                 (None, 64, 64, 128)  0           conv2d_14[0][0]                  
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, 64, 64, 128)  0           re_lu_14[0][0]                   
__________________________________________________________________________________________________
conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 64) 32832       dropout_14[0][0]                 
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 128, 128, 128 0           conv2d_transpose_3[0][0]         
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 128, 128, 64) 73792       concatenate_3[0][0]              
__________________________________________________________________________________________________
re_lu_15 (ReLU)                 (None, 128, 128, 64) 0           conv2d_15[0][0]                  
__________________________________________________________________________________________________
dropout_15 (Dropout)            (None, 128, 128, 64) 0           re_lu_15[0][0]                   
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 128, 128, 64) 36928       dropout_15[0][0]                 
__________________________________________________________________________________________________
re_lu_16 (ReLU)                 (None, 128, 128, 64) 0           conv2d_16[0][0]                  
__________________________________________________________________________________________________
dropout_16 (Dropout)            (None, 128, 128, 64) 0           re_lu_16[0][0]                   
__________________________________________________________________________________________________
conv2d_transpose_4 (Conv2DTrans (None, 256, 256, 32) 8224        dropout_16[0][0]                 
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 256, 256, 64) 0           conv2d_transpose_4[0][0]         
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 256, 256, 32) 18464       concatenate_4[0][0]              
__________________________________________________________________________________________________
re_lu_17 (ReLU)                 (None, 256, 256, 32) 0           conv2d_17[0][0]                  
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 256, 256, 32) 0           re_lu_17[0][0]                   
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 256, 256, 32) 9248        dropout_17[0][0]                 
__________________________________________________________________________________________________
re_lu_18 (ReLU)                 (None, 256, 256, 32) 0           conv2d_18[0][0]                  
__________________________________________________________________________________________________
dropout_18 (Dropout)            (None, 256, 256, 32) 0           re_lu_18[0][0]                   
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 256, 256, 1)  33          dropout_18[0][0]                 
==================================================================================================
Total params: 7,759,521
Trainable params: 7,759,521
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/1000
 - 17s - loss: 0.5519 - dice_coef: 0.4177 - val_loss: 0.4623 - val_dice_coef: 0.5038

Epoch 00001: val_dice_coef improved from -inf to 0.50376, saving model to baseline_unet_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 2/1000
 - 14s - loss: 0.4070 - dice_coef: 0.5613 - val_loss: 0.3733 - val_dice_coef: 0.6531

Epoch 00002: val_dice_coef improved from 0.50376 to 0.65311, saving model to baseline_unet_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 3/1000
 - 14s - loss: 0.3163 - dice_coef: 0.6850 - val_loss: 0.2646 - val_dice_coef: 0.7075

Epoch 00003: val_dice_coef improved from 0.65311 to 0.70749, saving model to baseline_unet_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 4/1000
 - 15s - loss: 0.2949 - dice_coef: 0.7260 - val_loss: 0.3203 - val_dice_coef: 0.7445

Epoch 00004: val_dice_coef improved from 0.70749 to 0.74454, saving model to baseline_unet_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 5/1000
 - 14s - loss: 0.2619 - dice_coef: 0.7684 - val_loss: 0.2412 - val_dice_coef: 0.7680

Epoch 00005: val_dice_coef improved from 0.74454 to 0.76803, saving model to baseline_unet_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 6/1000
 - 14s - loss: 0.2348 - dice_coef: 0.7962 - val_loss: 0.2661 - val_dice_coef: 0.7928

Epoch 00006: val_dice_coef improved from 0.76803 to 0.79279, saving model to baseline_unet_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 7/1000
 - 14s - loss: 0.2086 - dice_coef: 0.8246 - val_loss: 0.2198 - val_dice_coef: 0.8061

Epoch 00007: val_dice_coef improved from 0.79279 to 0.80613, saving model to baseline_unet_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 8/1000
 - 14s - loss: 0.1759 - dice_coef: 0.8590 - val_loss: 0.2624 - val_dice_coef: 0.8450

Epoch 00008: val_dice_coef improved from 0.80613 to 0.84500, saving model to baseline_unet_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 9/1000
 - 14s - loss: 0.1660 - dice_coef: 0.8696 - val_loss: 0.1682 - val_dice_coef: 0.8553

Epoch 00009: val_dice_coef improved from 0.84500 to 0.85526, saving model to baseline_unet_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 10/1000
 - 14s - loss: 0.1942 - dice_coef: 0.8457 - val_loss: 0.2087 - val_dice_coef: 0.8349

Epoch 00010: val_dice_coef did not improve from 0.85526
Epoch 11/1000
 - 15s - loss: 0.1779 - dice_coef: 0.8602 - val_loss: 0.3107 - val_dice_coef: 0.7888

Epoch 00011: val_dice_coef did not improve from 0.85526
Epoch 12/1000
 - 15s - loss: 0.1525 - dice_coef: 0.8783 - val_loss: 0.2604 - val_dice_coef: 0.8633

Epoch 00012: val_dice_coef improved from 0.85526 to 0.86329, saving model to baseline_unet_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 13/1000
 - 14s - loss: 0.1512 - dice_coef: 0.8846 - val_loss: 0.1716 - val_dice_coef: 0.8604

Epoch 00013: val_dice_coef did not improve from 0.86329
Epoch 14/1000
 - 14s - loss: 0.1453 - dice_coef: 0.8857 - val_loss: 0.1794 - val_dice_coef: 0.8592

Epoch 00014: val_dice_coef did not improve from 0.86329
Epoch 15/1000
 - 14s - loss: 0.1404 - dice_coef: 0.8890 - val_loss: 0.1684 - val_dice_coef: 0.8649

Epoch 00015: val_dice_coef improved from 0.86329 to 0.86488, saving model to baseline_unet_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 16/1000
 - 14s - loss: 0.1575 - dice_coef: 0.8785 - val_loss: 0.1471 - val_dice_coef: 0.8803

Epoch 00016: val_dice_coef improved from 0.86488 to 0.88025, saving model to baseline_unet_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 17/1000
 - 14s - loss: 0.1415 - dice_coef: 0.8874 - val_loss: 0.2970 - val_dice_coef: 0.8702

Epoch 00017: val_dice_coef did not improve from 0.88025
Epoch 18/1000
 - 14s - loss: 0.1198 - dice_coef: 0.9064 - val_loss: 0.3009 - val_dice_coef: 0.8315

Epoch 00018: val_dice_coef did not improve from 0.88025
Epoch 19/1000
 - 14s - loss: 0.1291 - dice_coef: 0.8986 - val_loss: 0.1422 - val_dice_coef: 0.8831

Epoch 00019: val_dice_coef improved from 0.88025 to 0.88308, saving model to baseline_unet_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 20/1000
 - 14s - loss: 0.1316 - dice_coef: 0.8988 - val_loss: 0.2148 - val_dice_coef: 0.8488

Epoch 00020: val_dice_coef did not improve from 0.88308
Epoch 21/1000
 - 14s - loss: 0.1193 - dice_coef: 0.9065 - val_loss: 0.2386 - val_dice_coef: 0.8670

Epoch 00021: val_dice_coef did not improve from 0.88308
Epoch 22/1000
 - 14s - loss: 0.1201 - dice_coef: 0.9060 - val_loss: 0.2940 - val_dice_coef: 0.8511

Epoch 00022: val_dice_coef did not improve from 0.88308

Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
Epoch 23/1000
 - 14s - loss: 0.1305 - dice_coef: 0.9016 - val_loss: 0.1546 - val_dice_coef: 0.8835

Epoch 00023: val_dice_coef improved from 0.88308 to 0.88351, saving model to baseline_unet_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 24/1000
 - 14s - loss: 0.1135 - dice_coef: 0.9113 - val_loss: 0.1698 - val_dice_coef: 0.8892

Epoch 00024: val_dice_coef improved from 0.88351 to 0.88924, saving model to baseline_unet_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 25/1000
 - 14s - loss: 0.1156 - dice_coef: 0.9133 - val_loss: 0.2250 - val_dice_coef: 0.8675

Epoch 00025: val_dice_coef did not improve from 0.88924
Epoch 26/1000
 - 14s - loss: 0.0973 - dice_coef: 0.9239 - val_loss: 0.2185 - val_dice_coef: 0.8754

Epoch 00026: val_dice_coef did not improve from 0.88924
Epoch 27/1000
 - 14s - loss: 0.1023 - dice_coef: 0.9223 - val_loss: 0.2187 - val_dice_coef: 0.8814

Epoch 00027: val_dice_coef did not improve from 0.88924

Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
Epoch 28/1000
 - 14s - loss: 0.0883 - dice_coef: 0.9284 - val_loss: 0.2807 - val_dice_coef: 0.8577

Epoch 00028: val_dice_coef did not improve from 0.88924
Epoch 29/1000
 - 15s - loss: 0.1028 - dice_coef: 0.9237 - val_loss: 0.1807 - val_dice_coef: 0.8894

Epoch 00029: val_dice_coef improved from 0.88924 to 0.88944, saving model to baseline_unet_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 30/1000
 - 14s - loss: 0.1072 - dice_coef: 0.9187 - val_loss: 0.1979 - val_dice_coef: 0.8817

Epoch 00030: val_dice_coef did not improve from 0.88944
Epoch 31/1000
 - 14s - loss: 0.1007 - dice_coef: 0.9243 - val_loss: 0.2290 - val_dice_coef: 0.8763

Epoch 00031: val_dice_coef did not improve from 0.88944
Epoch 32/1000
 - 15s - loss: 0.1059 - dice_coef: 0.9200 - val_loss: 0.1612 - val_dice_coef: 0.8895

Epoch 00032: val_dice_coef improved from 0.88944 to 0.88945, saving model to baseline_unet_do_0.0_activation_ReLU_weights.best.hdf5

Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.
Epoch 33/1000
 - 15s - loss: 0.0877 - dice_coef: 0.9262 - val_loss: 0.2528 - val_dice_coef: 0.8630

Epoch 00033: val_dice_coef did not improve from 0.88945
Epoch 34/1000
 - 15s - loss: 0.1070 - dice_coef: 0.9197 - val_loss: 0.2186 - val_dice_coef: 0.8730

Epoch 00034: val_dice_coef did not improve from 0.88945
Epoch 35/1000
 - 14s - loss: 0.0914 - dice_coef: 0.9249 - val_loss: 0.2207 - val_dice_coef: 0.8823

Epoch 00035: val_dice_coef did not improve from 0.88945

Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.
Epoch 36/1000
 - 14s - loss: 0.0933 - dice_coef: 0.9242 - val_loss: 0.1816 - val_dice_coef: 0.8856

Epoch 00036: val_dice_coef did not improve from 0.88945
Epoch 37/1000
 - 15s - loss: 0.1127 - dice_coef: 0.9186 - val_loss: 0.1398 - val_dice_coef: 0.9081

Epoch 00037: val_dice_coef improved from 0.88945 to 0.90806, saving model to baseline_unet_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 38/1000
 - 14s - loss: 0.1038 - dice_coef: 0.9214 - val_loss: 0.1605 - val_dice_coef: 0.8946

Epoch 00038: val_dice_coef did not improve from 0.90806
Epoch 39/1000
 - 15s - loss: 0.0948 - dice_coef: 0.9230 - val_loss: 0.2103 - val_dice_coef: 0.8764

Epoch 00039: val_dice_coef did not improve from 0.90806
Epoch 40/1000
 - 15s - loss: 0.1028 - dice_coef: 0.9218 - val_loss: 0.2932 - val_dice_coef: 0.8516

Epoch 00040: val_dice_coef did not improve from 0.90806

Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.
Epoch 41/1000
 - 15s - loss: 0.0925 - dice_coef: 0.9275 - val_loss: 0.2274 - val_dice_coef: 0.8733

Epoch 00041: val_dice_coef did not improve from 0.90806
Epoch 42/1000
 - 14s - loss: 0.0907 - dice_coef: 0.9250 - val_loss: 0.3821 - val_dice_coef: 0.8269

Epoch 00042: val_dice_coef did not improve from 0.90806
Epoch 00042: early stopping
