Model : baseline_unet_aug_do_0.0_activation_ReLU_
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 256, 256, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 256, 256, 32) 320         input_1[0][0]                    
__________________________________________________________________________________________________
re_lu_1 (ReLU)                  (None, 256, 256, 32) 0           conv2d_1[0][0]                   
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 256, 256, 32) 0           re_lu_1[0][0]                    
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 256, 256, 32) 9248        dropout_1[0][0]                  
__________________________________________________________________________________________________
re_lu_2 (ReLU)                  (None, 256, 256, 32) 0           conv2d_2[0][0]                   
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 256, 256, 32) 0           re_lu_2[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 32) 0           dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 128, 128, 64) 18496       max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
re_lu_3 (ReLU)                  (None, 128, 128, 64) 0           conv2d_3[0][0]                   
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 128, 128, 64) 0           re_lu_3[0][0]                    
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 128, 128, 64) 36928       dropout_3[0][0]                  
__________________________________________________________________________________________________
re_lu_4 (ReLU)                  (None, 128, 128, 64) 0           conv2d_4[0][0]                   
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 128, 128, 64) 0           re_lu_4[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 64)   0           dropout_4[0][0]                  
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
re_lu_5 (ReLU)                  (None, 64, 64, 128)  0           conv2d_5[0][0]                   
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 64, 64, 128)  0           re_lu_5[0][0]                    
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 64, 64, 128)  147584      dropout_5[0][0]                  
__________________________________________________________________________________________________
re_lu_6 (ReLU)                  (None, 64, 64, 128)  0           conv2d_6[0][0]                   
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 64, 64, 128)  0           re_lu_6[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 128)  0           dropout_6[0][0]                  
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
re_lu_7 (ReLU)                  (None, 32, 32, 256)  0           conv2d_7[0][0]                   
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 32, 32, 256)  0           re_lu_7[0][0]                    
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 32, 32, 256)  590080      dropout_7[0][0]                  
__________________________________________________________________________________________________
re_lu_8 (ReLU)                  (None, 32, 32, 256)  0           conv2d_8[0][0]                   
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 32, 32, 256)  0           re_lu_8[0][0]                    
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 256)  0           dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 16, 16, 512)  1180160     max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
re_lu_9 (ReLU)                  (None, 16, 16, 512)  0           conv2d_9[0][0]                   
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 16, 16, 512)  0           re_lu_9[0][0]                    
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 16, 16, 512)  2359808     dropout_9[0][0]                  
__________________________________________________________________________________________________
re_lu_10 (ReLU)                 (None, 16, 16, 512)  0           conv2d_10[0][0]                  
__________________________________________________________________________________________________
dropout_10 (Dropout)            (None, 16, 16, 512)  0           re_lu_10[0][0]                   
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 256)  524544      dropout_10[0][0]                 
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 32, 32, 512)  0           conv2d_transpose_1[0][0]         
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 32, 32, 256)  1179904     concatenate_1[0][0]              
__________________________________________________________________________________________________
re_lu_11 (ReLU)                 (None, 32, 32, 256)  0           conv2d_11[0][0]                  
__________________________________________________________________________________________________
dropout_11 (Dropout)            (None, 32, 32, 256)  0           re_lu_11[0][0]                   
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 32, 32, 256)  590080      dropout_11[0][0]                 
__________________________________________________________________________________________________
re_lu_12 (ReLU)                 (None, 32, 32, 256)  0           conv2d_12[0][0]                  
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 32, 32, 256)  0           re_lu_12[0][0]                   
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 128)  131200      dropout_12[0][0]                 
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 64, 64, 256)  0           conv2d_transpose_2[0][0]         
                                                                 dropout_6[0][0]                  
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 64, 64, 128)  295040      concatenate_2[0][0]              
__________________________________________________________________________________________________
re_lu_13 (ReLU)                 (None, 64, 64, 128)  0           conv2d_13[0][0]                  
__________________________________________________________________________________________________
dropout_13 (Dropout)            (None, 64, 64, 128)  0           re_lu_13[0][0]                   
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 64, 64, 128)  147584      dropout_13[0][0]                 
__________________________________________________________________________________________________
re_lu_14 (ReLU)                 (None, 64, 64, 128)  0           conv2d_14[0][0]                  
__________________________________________________________________________________________________
dropout_14 (Dropout)            (None, 64, 64, 128)  0           re_lu_14[0][0]                   
__________________________________________________________________________________________________
conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 64) 32832       dropout_14[0][0]                 
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 128, 128, 128 0           conv2d_transpose_3[0][0]         
                                                                 dropout_4[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 128, 128, 64) 73792       concatenate_3[0][0]              
__________________________________________________________________________________________________
re_lu_15 (ReLU)                 (None, 128, 128, 64) 0           conv2d_15[0][0]                  
__________________________________________________________________________________________________
dropout_15 (Dropout)            (None, 128, 128, 64) 0           re_lu_15[0][0]                   
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 128, 128, 64) 36928       dropout_15[0][0]                 
__________________________________________________________________________________________________
re_lu_16 (ReLU)                 (None, 128, 128, 64) 0           conv2d_16[0][0]                  
__________________________________________________________________________________________________
dropout_16 (Dropout)            (None, 128, 128, 64) 0           re_lu_16[0][0]                   
__________________________________________________________________________________________________
conv2d_transpose_4 (Conv2DTrans (None, 256, 256, 32) 8224        dropout_16[0][0]                 
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 256, 256, 64) 0           conv2d_transpose_4[0][0]         
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 256, 256, 32) 18464       concatenate_4[0][0]              
__________________________________________________________________________________________________
re_lu_17 (ReLU)                 (None, 256, 256, 32) 0           conv2d_17[0][0]                  
__________________________________________________________________________________________________
dropout_17 (Dropout)            (None, 256, 256, 32) 0           re_lu_17[0][0]                   
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 256, 256, 32) 9248        dropout_17[0][0]                 
__________________________________________________________________________________________________
re_lu_18 (ReLU)                 (None, 256, 256, 32) 0           conv2d_18[0][0]                  
__________________________________________________________________________________________________
dropout_18 (Dropout)            (None, 256, 256, 32) 0           re_lu_18[0][0]                   
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 256, 256, 1)  33          dropout_18[0][0]                 
==================================================================================================
Total params: 7,759,521
Trainable params: 7,759,521
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/1000
 - 17s - loss: 0.5798 - dice_coef: 0.4316 - val_loss: 0.4401 - val_dice_coef: 0.4846

Epoch 00001: val_dice_coef improved from -inf to 0.48455, saving model to baseline_unet_aug_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 2/1000
 - 14s - loss: 0.3896 - dice_coef: 0.6010 - val_loss: 0.3309 - val_dice_coef: 0.6606

Epoch 00002: val_dice_coef improved from 0.48455 to 0.66056, saving model to baseline_unet_aug_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 3/1000
 - 14s - loss: 0.3206 - dice_coef: 0.6873 - val_loss: 0.3143 - val_dice_coef: 0.6805

Epoch 00003: val_dice_coef improved from 0.66056 to 0.68054, saving model to baseline_unet_aug_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 4/1000
 - 14s - loss: 0.3037 - dice_coef: 0.7102 - val_loss: 0.2653 - val_dice_coef: 0.7415

Epoch 00004: val_dice_coef improved from 0.68054 to 0.74149, saving model to baseline_unet_aug_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 5/1000
 - 14s - loss: 0.2819 - dice_coef: 0.7444 - val_loss: 0.3152 - val_dice_coef: 0.7253

Epoch 00005: val_dice_coef did not improve from 0.74149
Epoch 6/1000
 - 14s - loss: 0.2627 - dice_coef: 0.7522 - val_loss: 0.2548 - val_dice_coef: 0.7741

Epoch 00006: val_dice_coef improved from 0.74149 to 0.77410, saving model to baseline_unet_aug_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 7/1000
 - 14s - loss: 0.2646 - dice_coef: 0.7610 - val_loss: 0.2222 - val_dice_coef: 0.7760

Epoch 00007: val_dice_coef improved from 0.77410 to 0.77602, saving model to baseline_unet_aug_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 8/1000
 - 14s - loss: 0.2608 - dice_coef: 0.7694 - val_loss: 0.2620 - val_dice_coef: 0.7661

Epoch 00008: val_dice_coef did not improve from 0.77602
Epoch 9/1000
 - 15s - loss: 0.2488 - dice_coef: 0.7727 - val_loss: 0.2965 - val_dice_coef: 0.7321

Epoch 00009: val_dice_coef did not improve from 0.77602
Epoch 10/1000
 - 15s - loss: 0.2676 - dice_coef: 0.7580 - val_loss: 0.2247 - val_dice_coef: 0.7963

Epoch 00010: val_dice_coef improved from 0.77602 to 0.79625, saving model to baseline_unet_aug_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 11/1000
 - 14s - loss: 0.2249 - dice_coef: 0.8074 - val_loss: 0.2573 - val_dice_coef: 0.7607

Epoch 00011: val_dice_coef did not improve from 0.79625
Epoch 12/1000
 - 15s - loss: 0.2389 - dice_coef: 0.7926 - val_loss: 0.1819 - val_dice_coef: 0.8270

Epoch 00012: val_dice_coef improved from 0.79625 to 0.82696, saving model to baseline_unet_aug_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 13/1000
 - 15s - loss: 0.2172 - dice_coef: 0.8126 - val_loss: 0.1659 - val_dice_coef: 0.8284

Epoch 00013: val_dice_coef improved from 0.82696 to 0.82840, saving model to baseline_unet_aug_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 14/1000
 - 15s - loss: 0.2002 - dice_coef: 0.8229 - val_loss: 0.1757 - val_dice_coef: 0.8558

Epoch 00014: val_dice_coef improved from 0.82840 to 0.85580, saving model to baseline_unet_aug_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 15/1000
 - 15s - loss: 0.1865 - dice_coef: 0.8478 - val_loss: 0.1459 - val_dice_coef: 0.8557

Epoch 00015: val_dice_coef did not improve from 0.85580
Epoch 16/1000
 - 15s - loss: 0.1915 - dice_coef: 0.8395 - val_loss: 0.2346 - val_dice_coef: 0.8263

Epoch 00016: val_dice_coef did not improve from 0.85580
Epoch 17/1000
 - 15s - loss: 0.1642 - dice_coef: 0.8657 - val_loss: 0.2144 - val_dice_coef: 0.8599

Epoch 00017: val_dice_coef improved from 0.85580 to 0.85987, saving model to baseline_unet_aug_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 18/1000
 - 15s - loss: 0.1751 - dice_coef: 0.8557 - val_loss: 0.1224 - val_dice_coef: 0.8876

Epoch 00018: val_dice_coef improved from 0.85987 to 0.88759, saving model to baseline_unet_aug_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 19/1000
 - 15s - loss: 0.1745 - dice_coef: 0.8568 - val_loss: 0.1769 - val_dice_coef: 0.8761

Epoch 00019: val_dice_coef did not improve from 0.88759
Epoch 20/1000
 - 15s - loss: 0.1740 - dice_coef: 0.8581 - val_loss: 0.1617 - val_dice_coef: 0.8560

Epoch 00020: val_dice_coef did not improve from 0.88759
Epoch 21/1000
 - 15s - loss: 0.1637 - dice_coef: 0.8707 - val_loss: 0.1502 - val_dice_coef: 0.8812

Epoch 00021: val_dice_coef did not improve from 0.88759

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.
Epoch 22/1000
 - 15s - loss: 0.1521 - dice_coef: 0.8746 - val_loss: 0.1145 - val_dice_coef: 0.8978

Epoch 00022: val_dice_coef improved from 0.88759 to 0.89785, saving model to baseline_unet_aug_do_0.0_activation_ReLU_weights.best.hdf5
Epoch 23/1000
 - 15s - loss: 0.1491 - dice_coef: 0.8816 - val_loss: 0.1451 - val_dice_coef: 0.8907

Epoch 00023: val_dice_coef did not improve from 0.89785
Epoch 24/1000
 - 14s - loss: 0.1546 - dice_coef: 0.8807 - val_loss: 0.1815 - val_dice_coef: 0.8622

Epoch 00024: val_dice_coef did not improve from 0.89785
Epoch 25/1000
 - 15s - loss: 0.1346 - dice_coef: 0.8917 - val_loss: 0.1752 - val_dice_coef: 0.8794

Epoch 00025: val_dice_coef did not improve from 0.89785

Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.
Epoch 26/1000
 - 15s - loss: 0.1318 - dice_coef: 0.8922 - val_loss: 0.1144 - val_dice_coef: 0.8971

Epoch 00026: val_dice_coef did not improve from 0.89785
Epoch 27/1000
 - 15s - loss: 0.1448 - dice_coef: 0.8864 - val_loss: 0.1829 - val_dice_coef: 0.8747

Epoch 00027: val_dice_coef did not improve from 0.89785
Epoch 00027: early stopping
